{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b7788f",
   "metadata": {},
   "source": [
    "# Psoriasis Disease Detection using Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cac57",
   "metadata": {},
   "source": [
    "Psoriasis, affecting 125 million globally, causes rashes, scaly patches, and itchy skin. Our research creates a dataset with seven psoriasis classes, using InceptionResNetV2 and InceptionV3 for accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd809d9c",
   "metadata": {},
   "source": [
    "## Detection using the InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbe2e0",
   "metadata": {},
   "source": [
    "Inception-ResNet V2 is a deep convolutional neural network combining the strengths of Inception modules and residual connections. It incorporates residual connections to improve training speed and stability, while the Inception modules enhance feature extraction efficiency. This architecture achieves high accuracy in image classification tasks and is widely used in medical image analysis and other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac92b1",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries and Transfer Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e744be0",
   "metadata": {
    "id": "9e744be0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55eacbe",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b21975",
   "metadata": {},
   "source": [
    "The dataset includes seven classes of psoriasis diseases sourced from publicly available datasets such as SKIN LESION, ISIC, and DEMANET. It sets paths for training, testing, and validation datasets and initializes data generators. The training generator applies rescaling, shearing, zooming, and horizontal flipping for data augmentation, while the testing and validation generators only rescale the images. All generators resize images to 224x224 pixels, prepare them in batches of 32, and use categorical classification mode. The output shows the dataset statistics: 2800 images for training, 608 for validation, and 597 for testing, distributed among the seven psoriasis classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a810267",
   "metadata": {
    "id": "7a810267",
    "outputId": "a38dd5a2-d000-4a28-e5a2-afe42536994e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 images belonging to 7 classes.\n",
      "Found 608 images belonging to 7 classes.\n",
      "Found 597 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = \"\\path\"\n",
    "test_path  = \"\\path\"\n",
    "val_path   = \"\\path\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_path,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(val_path,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5daf41",
   "metadata": {},
   "source": [
    "### Building the InceptionResNetV2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e46bff",
   "metadata": {},
   "source": [
    "Initializing a transfer learning model using Inception-ResNet V2 pre-trained on ImageNet for image classification. It excludes the top classification layers initially and adds a global average pooling layer to reduce spatial dimensions, followed by a dense layer with 1024 units and ReLU activation. The final dense layer has softmax activation for categorical prediction based on the number of classes in the training data. The model architecture is defined with the base model's input and custom output layers. All layers from the Inception-ResNet V2 base model are frozen to retain pre-learned features during training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648cc29",
   "metadata": {},
   "source": [
    "### Compiling the Model with RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb003f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab4842",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ebe65",
   "metadata": {
    "id": "1c9ebe65",
    "outputId": "c36b13dc-07a2-42cc-e94b-de0b579a2d6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSAI\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 36s 275ms/step - loss: 2.1078 - accuracy: 0.5560 - val_loss: 0.8400 - val_accuracy: 0.6632\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 0.8306 - accuracy: 0.7265 - val_loss: 0.5047 - val_accuracy: 0.8247\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 16s 183ms/step - loss: 0.6425 - accuracy: 0.7735 - val_loss: 0.5191 - val_accuracy: 0.8160\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.5265 - accuracy: 0.8121 - val_loss: 0.3319 - val_accuracy: 0.8663\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.4246 - accuracy: 0.8504 - val_loss: 0.3255 - val_accuracy: 0.8837\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 0.3778 - accuracy: 0.8645 - val_loss: 0.2781 - val_accuracy: 0.8958\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.3256 - accuracy: 0.8913 - val_loss: 0.4347 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 0.2688 - accuracy: 0.9086 - val_loss: 0.2774 - val_accuracy: 0.8924\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.2642 - accuracy: 0.9086 - val_loss: 0.2222 - val_accuracy: 0.9201\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 16s 185ms/step - loss: 0.2343 - accuracy: 0.9169 - val_loss: 0.1905 - val_accuracy: 0.9340\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 16s 185ms/step - loss: 0.1862 - accuracy: 0.9368 - val_loss: 0.2304 - val_accuracy: 0.9271\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 0.1972 - accuracy: 0.9303 - val_loss: 0.2149 - val_accuracy: 0.9479\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.2058 - accuracy: 0.9288 - val_loss: 0.1739 - val_accuracy: 0.9392\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 0.1618 - accuracy: 0.9436 - val_loss: 0.1707 - val_accuracy: 0.9549\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.1655 - accuracy: 0.9458 - val_loss: 0.3233 - val_accuracy: 0.9062\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 0.1759 - accuracy: 0.9418 - val_loss: 0.1625 - val_accuracy: 0.9497\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.1486 - accuracy: 0.9530 - val_loss: 0.2412 - val_accuracy: 0.9288\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 16s 186ms/step - loss: 0.1548 - accuracy: 0.9491 - val_loss: 0.1422 - val_accuracy: 0.9497\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 16s 184ms/step - loss: 0.1340 - accuracy: 0.9577 - val_loss: 0.3194 - val_accuracy: 0.8872\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.1196 - accuracy: 0.9595 - val_loss: 0.1904 - val_accuracy: 0.9392\n",
      "19/19 [==============================] - 3s 131ms/step - loss: 0.1693 - accuracy: 0.9490\n",
      "Test loss: 0.16933877766132355\n",
      "Test accuracy: 0.9490131735801697\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9d6be",
   "metadata": {},
   "source": [
    "### Building and Compiling the same Model using the Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d061a43",
   "metadata": {},
   "source": [
    "Initializing a transfer learning model using Inception-ResNet V2, pretrained on ImageNet, for image classification tasks. It excludes the top classification layers by default, adds a global average pooling layer for spatial reduction, and appends a dense layer with 1024 units and ReLU activation. The final dense layer, using softmax activation, predicts categories based on the number of classes in the training data. The model is compiled with the Adam optimizer, learning rate set to 0.001, categorical cross-entropy loss function, and accuracy as the evaluation metric. All layers from the Inception-ResNet V2 base model are frozen to retain pre-learned features during training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c239ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc03c7e",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6667f",
   "metadata": {
    "id": "84e6667f",
    "outputId": "5c445164-8281-4d4b-9d4e-3cb56e1459d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSAI\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "259/259 [==============================] - 72s 259ms/step - loss: 2.0898 - accuracy: 0.3736 - val_loss: 1.6732 - val_accuracy: 0.4626\n",
      "Epoch 2/20\n",
      "259/259 [==============================] - 66s 253ms/step - loss: 1.5719 - accuracy: 0.4898 - val_loss: 1.4989 - val_accuracy: 0.5098\n",
      "Epoch 3/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 1.4250 - accuracy: 0.5262 - val_loss: 1.3968 - val_accuracy: 0.5461\n",
      "Epoch 4/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 1.3235 - accuracy: 0.5535 - val_loss: 1.3995 - val_accuracy: 0.5487\n",
      "Epoch 5/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 1.2776 - accuracy: 0.5716 - val_loss: 1.3111 - val_accuracy: 0.5705\n",
      "Epoch 6/20\n",
      "259/259 [==============================] - 65s 252ms/step - loss: 1.2044 - accuracy: 0.5926 - val_loss: 1.3606 - val_accuracy: 0.5647\n",
      "Epoch 7/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 1.1800 - accuracy: 0.5932 - val_loss: 1.1676 - val_accuracy: 0.6097\n",
      "Epoch 8/20\n",
      "259/259 [==============================] - 65s 253ms/step - loss: 1.1360 - accuracy: 0.6149 - val_loss: 1.2055 - val_accuracy: 0.5945\n",
      "Epoch 9/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 1.0915 - accuracy: 0.6248 - val_loss: 1.1329 - val_accuracy: 0.6141\n",
      "Epoch 10/20\n",
      "259/259 [==============================] - 65s 252ms/step - loss: 1.0771 - accuracy: 0.6304 - val_loss: 1.0960 - val_accuracy: 0.6344\n",
      "Epoch 11/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 1.0427 - accuracy: 0.6407 - val_loss: 1.0461 - val_accuracy: 0.6363\n",
      "Epoch 12/20\n",
      "259/259 [==============================] - 65s 253ms/step - loss: 1.0133 - accuracy: 0.6515 - val_loss: 1.0904 - val_accuracy: 0.6294\n",
      "Epoch 13/20\n",
      "259/259 [==============================] - 65s 252ms/step - loss: 0.9798 - accuracy: 0.6533 - val_loss: 1.1287 - val_accuracy: 0.6126\n",
      "Epoch 14/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 0.9617 - accuracy: 0.6654 - val_loss: 1.0661 - val_accuracy: 0.6377\n",
      "Epoch 15/20\n",
      "259/259 [==============================] - 65s 250ms/step - loss: 0.9794 - accuracy: 0.6535 - val_loss: 1.0759 - val_accuracy: 0.6246\n",
      "Epoch 16/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 0.9259 - accuracy: 0.6747 - val_loss: 1.0211 - val_accuracy: 0.6472\n",
      "Epoch 17/20\n",
      "259/259 [==============================] - 65s 252ms/step - loss: 0.9426 - accuracy: 0.6705 - val_loss: 1.0690 - val_accuracy: 0.6305\n",
      "Epoch 18/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 0.8984 - accuracy: 0.6905 - val_loss: 1.0139 - val_accuracy: 0.6515\n",
      "Epoch 19/20\n",
      "259/259 [==============================] - 66s 253ms/step - loss: 0.8782 - accuracy: 0.6866 - val_loss: 0.9965 - val_accuracy: 0.6679\n",
      "Epoch 20/20\n",
      "259/259 [==============================] - 65s 251ms/step - loss: 0.8584 - accuracy: 0.6939 - val_loss: 0.9766 - val_accuracy: 0.6653\n",
      "87/87 [==============================] - 11s 120ms/step - loss: 0.9750 - accuracy: 0.6554\n",
      "Test loss: 0.9749826192855835\n",
      "Test accuracy: 0.6553713083267212\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d77c4",
   "metadata": {},
   "source": [
    "Evaluating the trained Inception-ResNet V2 model on the training, validation, and test datasets using the evaluate method. It computes and retrieves the loss and accuracy metrics for each dataset. The train_generator, val_generator, and test_generator are used as input to evaluate the model on their respective datasets. The results are printed to the console, displaying the training loss and accuracy, validation loss and accuracy, and test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cc13b-ce83-43d9-b6ef-dc9179cc4d71",
   "metadata": {
    "id": "a93cc13b-ce83-43d9-b6ef-dc9179cc4d71",
    "outputId": "414c666f-f3eb-4788-f7e6-ec94e7160031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 157ms/step - loss: 0.0858 - accuracy: 0.9675\n",
      "19/19 [==============================] - 2s 124ms/step - loss: 0.1908 - accuracy: 0.9380\n",
      "19/19 [==============================] - 2s 117ms/step - loss: 0.1693 - accuracy: 0.9490\n",
      "Train loss:, val loss: test loss:  0.08580939471721649 0.1908438354730606 0.16933879256248474\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9674999713897705 0.9380234479904175 0.9490131735801697\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80d94c",
   "metadata": {},
   "source": [
    "## Detection using the InceptionV3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc68cd",
   "metadata": {},
   "source": [
    "InceptionV3 is a deep convolutional neural network architecture developed by Google, renowned for its efficiency and accuracy in image classification and object detection tasks. It utilizes various convolutional filter sizes and auxiliary classifiers to capture multi-scale features effectively, making it suitable for diverse computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf2dfb",
   "metadata": {},
   "source": [
    "### Building the InceptionV3 Model and Compiling the Model using Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f01504",
   "metadata": {},
   "source": [
    "Building a transfer learning model using the InceptionV3 architecture pre-trained on ImageNet for image classification tasks. It initializes InceptionV3 without its top classification layers and adds a global average pooling layer followed by a dense layer with 1024 units and ReLU activation. The final dense layer predicts classes based on the number of classes in the training data using softmax activation. The model's base layers are frozen to retain pre-trained weights. It is compiled with the Adam optimizer, a learning rate of 0.001, categorical cross-entropy loss, and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d1727",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0e84a",
   "metadata": {
    "id": "b7d0e84a",
    "outputId": "b9bb04e5-2769-4ebb-b242-7fa1360c786b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSAI\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 17s 174ms/step - loss: 1.0717 - accuracy: 0.6770 - val_loss: 0.5600 - val_accuracy: 0.8142\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.4492 - accuracy: 0.8483 - val_loss: 0.3915 - val_accuracy: 0.8646\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 0.3631 - accuracy: 0.8714 - val_loss: 0.3801 - val_accuracy: 0.8628\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2705 - accuracy: 0.9053 - val_loss: 0.3193 - val_accuracy: 0.8941\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.2380 - accuracy: 0.9115 - val_loss: 0.2848 - val_accuracy: 0.9132\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.2083 - accuracy: 0.9267 - val_loss: 0.2901 - val_accuracy: 0.9062\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.2222 - accuracy: 0.9184 - val_loss: 0.2576 - val_accuracy: 0.9115\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1472 - accuracy: 0.9494 - val_loss: 0.3207 - val_accuracy: 0.9010\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1600 - accuracy: 0.9426 - val_loss: 0.2376 - val_accuracy: 0.9201\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1383 - accuracy: 0.9541 - val_loss: 0.2245 - val_accuracy: 0.9427\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 0.1379 - accuracy: 0.9494 - val_loss: 0.1792 - val_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1066 - accuracy: 0.9642 - val_loss: 0.2025 - val_accuracy: 0.9288\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1002 - accuracy: 0.9682 - val_loss: 0.2037 - val_accuracy: 0.9427\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.0997 - accuracy: 0.9682 - val_loss: 0.1739 - val_accuracy: 0.9497\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 0.1749 - val_accuracy: 0.9392\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.1954 - val_accuracy: 0.9462\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.0722 - accuracy: 0.9697 - val_loss: 0.1962 - val_accuracy: 0.9427\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.0678 - accuracy: 0.9758 - val_loss: 0.1757 - val_accuracy: 0.9531\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.0711 - accuracy: 0.9729 - val_loss: 0.2291 - val_accuracy: 0.9392\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.0752 - accuracy: 0.9745 - val_loss: 0.1978 - val_accuracy: 0.9410\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.1200 - accuracy: 0.9539\n",
      "Test loss: 0.11997473984956741\n",
      "Test accuracy: 0.9539473652839661\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c3435",
   "metadata": {},
   "source": [
    "Evaluating the trained InceptionV3 model on the training, validation, and test datasets using the evaluate method. It computes and retrieves the loss and accuracy metrics for each dataset and prints them to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b627ad-1afa-47a6-906b-631e57598d02",
   "metadata": {
    "id": "52b627ad-1afa-47a6-906b-631e57598d02",
    "outputId": "2b7722fb-53c9-49f3-9885-4ecd48927c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 153ms/step - loss: 0.0499 - accuracy: 0.9839\n",
      "19/19 [==============================] - 1s 64ms/step - loss: 0.1916 - accuracy: 0.9430\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.1200 - accuracy: 0.9539\n",
      "Train loss:, val loss: test loss:  0.0499376580119133 0.1915629357099533 0.11997473984956741\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9839285612106323 0.9430485963821411 0.9539473652839661\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c782b66",
   "metadata": {},
   "source": [
    "### Building the InceptionV3 Model and Compiling the Model using RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9645167",
   "metadata": {},
   "source": [
    "Building a transfer learning model using the InceptionV3 architecture pre-trained on ImageNet for image classification tasks. It initializes InceptionV3 without its top classification layers and adds a global average pooling layer followed by a dense layer with 1024 units and ReLU activation. The final dense layer predicts classes based on the number of classes in the training data using softmax activation. The model's base layers are frozen to retain pre-trained weights. It is compiled with the RMSprop optimizer, a learning rate of 0.001, categorical cross-entropy loss, and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "#x = base_model.layers.DropOut(0.1)(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4be1c4",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fc17a",
   "metadata": {
    "id": "505fc17a",
    "outputId": "e1862cdd-1a1e-47cc-824a-7c12be6e6e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 18s 177ms/step - loss: 1.9657 - accuracy: 0.5697 - val_loss: 0.6459 - val_accuracy: 0.7847\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.7905 - accuracy: 0.7341 - val_loss: 0.4434 - val_accuracy: 0.8403\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.5491 - accuracy: 0.8056 - val_loss: 0.3915 - val_accuracy: 0.8611\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.4815 - accuracy: 0.8277 - val_loss: 0.3945 - val_accuracy: 0.8420\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.3519 - accuracy: 0.8725 - val_loss: 0.4996 - val_accuracy: 0.8490\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.3235 - accuracy: 0.8833 - val_loss: 0.3708 - val_accuracy: 0.8785\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2896 - accuracy: 0.8970 - val_loss: 0.2083 - val_accuracy: 0.9288\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.2436 - accuracy: 0.9104 - val_loss: 0.2827 - val_accuracy: 0.9080\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2142 - accuracy: 0.9299 - val_loss: 0.3434 - val_accuracy: 0.8976\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1802 - accuracy: 0.9350 - val_loss: 0.2396 - val_accuracy: 0.9358\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1683 - accuracy: 0.9386 - val_loss: 0.2745 - val_accuracy: 0.9271\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1756 - accuracy: 0.9415 - val_loss: 0.1820 - val_accuracy: 0.9444\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1452 - accuracy: 0.9491 - val_loss: 0.2182 - val_accuracy: 0.9323\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1419 - accuracy: 0.9552 - val_loss: 0.2888 - val_accuracy: 0.9340\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1405 - accuracy: 0.9534 - val_loss: 0.3241 - val_accuracy: 0.9253\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1399 - accuracy: 0.9520 - val_loss: 0.4708 - val_accuracy: 0.8889\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1201 - accuracy: 0.9595 - val_loss: 0.5103 - val_accuracy: 0.9010\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 0.2674 - val_accuracy: 0.9462\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1089 - accuracy: 0.9686 - val_loss: 0.6197 - val_accuracy: 0.8594\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1058 - accuracy: 0.9693 - val_loss: 0.2260 - val_accuracy: 0.9444\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.0955 - accuracy: 0.9718 - val_loss: 0.2878 - val_accuracy: 0.9340\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1136 - accuracy: 0.9664 - val_loss: 0.2388 - val_accuracy: 0.9462\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.0836 - accuracy: 0.9711 - val_loss: 0.2635 - val_accuracy: 0.9462\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.0970 - accuracy: 0.9722 - val_loss: 0.2997 - val_accuracy: 0.9549\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.0892 - accuracy: 0.9689 - val_loss: 0.2398 - val_accuracy: 0.9444\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.0919 - accuracy: 0.9668 - val_loss: 0.3715 - val_accuracy: 0.9149\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 0.0904 - accuracy: 0.9783 - val_loss: 0.1696 - val_accuracy: 0.9601\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.0798 - accuracy: 0.9776 - val_loss: 0.3534 - val_accuracy: 0.9288\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.0677 - accuracy: 0.9798 - val_loss: 0.1628 - val_accuracy: 0.9705\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.0859 - accuracy: 0.9754 - val_loss: 0.2478 - val_accuracy: 0.9497\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.1590 - accuracy: 0.9622\n",
      "Test loss: 0.15901251137256622\n",
      "Test accuracy: 0.9621710777282715\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=30,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced7173",
   "metadata": {},
   "source": [
    "Evaluating the trained InceptionV3 model on the training, validation, and test datasets using the evaluate method. It computes and retrieves the loss and accuracy metrics for each dataset and prints them to the console in a clear format. Adjustments have been made to ensure the print statements correctly display the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb4a43-6ab5-4bdf-832d-77e8bfc41441",
   "metadata": {
    "id": "7abb4a43-6ab5-4bdf-832d-77e8bfc41441",
    "outputId": "d8e1f300-af88-4c66-88b5-76433a7b0d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 151ms/step - loss: 0.1125 - accuracy: 0.9711\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.2452 - accuracy: 0.9481\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.1590 - accuracy: 0.9622\n",
      "Train loss:, val loss: test loss:  0.11254952847957611 0.24523282051086426 0.15901249647140503\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9710714221000671 0.94807368516922 0.9621710777282715\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c98af",
   "metadata": {},
   "source": [
    "### Building the InceptionV3 Model using BatchNormalization and Compling the Model using Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86491a4",
   "metadata": {},
   "source": [
    "Adding a batch normalization layer and dropout regularization to improve generalization and reduce overfitting to this model architecture. The final dense layer with 512 units and ReLU activation enhances feature extraction capabilities. The base layers of InceptionV3 remain frozen to retain pre-trained weights. The model is compiled with the Adam optimizer, a learning rate of 0.001, categorical cross-entropy loss function, and accuracy metric for evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50638ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=  Dropout(0.4)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e90114",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e9445",
   "metadata": {
    "id": "0d5e9445",
    "outputId": "fbdfee19-468d-4120-ff30-14a720680432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 18s 176ms/step - loss: 0.9105 - accuracy: 0.7446 - val_loss: 0.4410 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.4645 - accuracy: 0.8537 - val_loss: 0.4014 - val_accuracy: 0.8785\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.3591 - accuracy: 0.8978 - val_loss: 0.2829 - val_accuracy: 0.9097\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.2993 - accuracy: 0.9111 - val_loss: 0.3165 - val_accuracy: 0.9028\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.2252 - accuracy: 0.9332 - val_loss: 0.2499 - val_accuracy: 0.9392\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.2298 - accuracy: 0.9281 - val_loss: 0.2324 - val_accuracy: 0.9497\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2257 - accuracy: 0.9364 - val_loss: 0.2844 - val_accuracy: 0.9427\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1991 - accuracy: 0.9364 - val_loss: 0.2884 - val_accuracy: 0.9410\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1505 - accuracy: 0.9541 - val_loss: 0.2136 - val_accuracy: 0.9583\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1391 - accuracy: 0.9530 - val_loss: 0.2545 - val_accuracy: 0.9497\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.1540 - accuracy: 0.9501 - val_loss: 0.1835 - val_accuracy: 0.9601\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1315 - accuracy: 0.9548 - val_loss: 0.2255 - val_accuracy: 0.9531\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1353 - accuracy: 0.9574 - val_loss: 0.2015 - val_accuracy: 0.9497\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.1299 - accuracy: 0.9628 - val_loss: 0.2461 - val_accuracy: 0.9601\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.1267 - accuracy: 0.9628 - val_loss: 0.1759 - val_accuracy: 0.9670\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1074 - accuracy: 0.9653 - val_loss: 0.1667 - val_accuracy: 0.9618\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.0986 - accuracy: 0.9686 - val_loss: 0.2816 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1076 - accuracy: 0.9675 - val_loss: 0.2124 - val_accuracy: 0.9549\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1067 - accuracy: 0.9671 - val_loss: 0.1834 - val_accuracy: 0.9653\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1092 - accuracy: 0.9632 - val_loss: 0.2058 - val_accuracy: 0.9531\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.0987 - accuracy: 0.9704\n",
      "Test loss: 0.09868647903203964\n",
      "Test accuracy: 0.9703947305679321\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466d304",
   "metadata": {},
   "source": [
    "Evaluating the trained model (model) on the training (train_generator), validation (val_generator), and test (test_generator) datasets using the evaluate method. It calculates and retrieves the loss and accuracy metrics for each dataset and prints them in a clear format. Adjustments have been made to ensure the print statements display the evaluation results correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd2be0-9caf-4b65-89fb-6ecb52c6635e",
   "metadata": {
    "id": "e0cd2be0-9caf-4b65-89fb-6ecb52c6635e",
    "outputId": "c0461cdf-5670-413b-88ad-a7d0a366b95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 152ms/step - loss: 0.0316 - accuracy: 0.9904\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.1986 - accuracy: 0.9548\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.0987 - accuracy: 0.9704\n",
      "Train loss:, val loss: test loss:  0.03159834071993828 0.19860288500785828 0.09868647158145905\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9903571605682373 0.9547738432884216 0.9703947305679321\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6157462",
   "metadata": {},
   "source": [
    "### InceptionV3 Model with 768 Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244375e",
   "metadata": {},
   "source": [
    "Incorporating a batch normalization layer and dropout regularization (40%) to enhance training stability and prevent overfitting. The final dense layer with 768 units and ReLU activation aims to capture more complex features from the base model's output. The base layers of InceptionV3 remain frozen to retain pre-trained weights. The model is compiled with the Adam optimizer, a learning rate of 0.001, categorical cross-entropy loss function, and accuracy metric for evaluation during training. Adjustments have been made for clarity and to align with best practices in model building and regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=  Dropout(0.4)(x)\n",
    "x = Dense(768, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10407210",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f280c97",
   "metadata": {
    "id": "9f280c97",
    "outputId": "287b3d24-4ab7-4f30-958c-77ae1a89920e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 17s 175ms/step - loss: 1.0248 - accuracy: 0.7504 - val_loss: 0.6572 - val_accuracy: 0.7865\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.5005 - accuracy: 0.8562 - val_loss: 0.3954 - val_accuracy: 0.8872\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.3954 - accuracy: 0.8851 - val_loss: 0.3144 - val_accuracy: 0.9253\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.3151 - accuracy: 0.9032 - val_loss: 0.2845 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.2600 - accuracy: 0.9155 - val_loss: 0.2216 - val_accuracy: 0.9462\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.2197 - accuracy: 0.9335 - val_loss: 0.2218 - val_accuracy: 0.9514\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2121 - accuracy: 0.9350 - val_loss: 0.3154 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.2198 - accuracy: 0.9393 - val_loss: 0.1788 - val_accuracy: 0.9601\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1639 - accuracy: 0.9469 - val_loss: 0.1942 - val_accuracy: 0.9653\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1453 - accuracy: 0.9534 - val_loss: 0.2029 - val_accuracy: 0.9583\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.1432 - accuracy: 0.9530 - val_loss: 0.2411 - val_accuracy: 0.9549\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1468 - accuracy: 0.9566 - val_loss: 0.2372 - val_accuracy: 0.9427\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1585 - accuracy: 0.9538 - val_loss: 0.1643 - val_accuracy: 0.9549\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1468 - accuracy: 0.9534 - val_loss: 0.2681 - val_accuracy: 0.9497\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.1292 - accuracy: 0.9608 - val_loss: 0.1480 - val_accuracy: 0.9583\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.1479 - accuracy: 0.9574 - val_loss: 0.2892 - val_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 166ms/step - loss: 0.1165 - accuracy: 0.9660 - val_loss: 0.1941 - val_accuracy: 0.9601\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.1044 - accuracy: 0.9682 - val_loss: 0.2015 - val_accuracy: 0.9618\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.1215 - accuracy: 0.9617 - val_loss: 0.2958 - val_accuracy: 0.9410\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.1223 - accuracy: 0.9632 - val_loss: 0.2408 - val_accuracy: 0.9583\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.1101 - accuracy: 0.9803\n",
      "Test loss: 0.11014298349618912\n",
      "Test accuracy: 0.9802631735801697\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea4765",
   "metadata": {},
   "source": [
    "Evaluating the trained InceptionV3-based model (model) on the training (train_generator), validation (val_generator), and test (test_generator) datasets using the evaluate method. It calculates and retrieves the loss and accuracy metrics for each dataset and prints them in a clear format. Adjustments have been made to ensure the print statements display the evaluation results correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e813ab-6a5a-4f51-9263-250fd5b5ca55",
   "metadata": {
    "id": "c7e813ab-6a5a-4f51-9263-250fd5b5ca55",
    "outputId": "e244278f-a92d-427c-83f2-14a4f4529832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 156ms/step - loss: 0.0420 - accuracy: 0.9850\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.2341 - accuracy: 0.9598\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.1101 - accuracy: 0.9803\n",
      "Train loss:, val loss: test loss:  0.041993625462055206 0.2340845912694931 0.11014299839735031\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9850000143051147 0.9597989916801453 0.9802631735801697\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8203cae",
   "metadata": {},
   "source": [
    "### InceptionV3 Model with 1024 Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdd2b5",
   "metadata": {},
   "source": [
    "Building a transfer learning model using the InceptionV3 architecture pre-trained on ImageNet for image classification. It initializes InceptionV3 without its top layers and adds a global average pooling layer, batch normalization for stability, a dropout layer with a rate of 0.4 for regularization, and a dense layer with 1024 units and ReLU activation for feature extraction. The final dense layer predicts classes based on the number of classes in the training data using softmax activation. All layers from the InceptionV3 base model are frozen to retain pre-trained weights. The model is compiled with the Adam optimizer, a learning rate of 0.001, categorical cross-entropy loss function, and accuracy metric for evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=  Dropout(0.4)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055701a1",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad9a1",
   "metadata": {
    "id": "96bad9a1",
    "outputId": "48b29572-c82e-49b4-c835-3f25bd25677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 18s 180ms/step - loss: 1.0500 - accuracy: 0.7460 - val_loss: 0.5652 - val_accuracy: 0.8073\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.5548 - accuracy: 0.8551 - val_loss: 0.3622 - val_accuracy: 0.8958\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.4243 - accuracy: 0.8790 - val_loss: 0.3421 - val_accuracy: 0.9028\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.3242 - accuracy: 0.9090 - val_loss: 0.2757 - val_accuracy: 0.9358\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.2872 - accuracy: 0.9162 - val_loss: 0.2527 - val_accuracy: 0.9444\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.2396 - accuracy: 0.9310 - val_loss: 0.3001 - val_accuracy: 0.9375\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.2531 - accuracy: 0.9281 - val_loss: 0.1988 - val_accuracy: 0.9514\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.1860 - accuracy: 0.9415 - val_loss: 0.2958 - val_accuracy: 0.9340\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.2385 - accuracy: 0.9335 - val_loss: 0.2898 - val_accuracy: 0.9497\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.2385 - accuracy: 0.9339 - val_loss: 0.2571 - val_accuracy: 0.9497\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.2119 - accuracy: 0.9458 - val_loss: 0.3206 - val_accuracy: 0.9410\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1716 - accuracy: 0.9516 - val_loss: 0.2814 - val_accuracy: 0.9358\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1229 - accuracy: 0.9650 - val_loss: 0.2679 - val_accuracy: 0.9462\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1848 - accuracy: 0.9454 - val_loss: 0.2876 - val_accuracy: 0.9392\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1525 - accuracy: 0.9552 - val_loss: 0.2214 - val_accuracy: 0.9392\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1221 - accuracy: 0.9639 - val_loss: 0.2023 - val_accuracy: 0.9618\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1111 - accuracy: 0.9693 - val_loss: 0.2138 - val_accuracy: 0.9601\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1024 - accuracy: 0.9660 - val_loss: 0.2128 - val_accuracy: 0.9635\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1050 - accuracy: 0.9675 - val_loss: 0.2985 - val_accuracy: 0.9549\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.1208 - accuracy: 0.9697 - val_loss: 0.2622 - val_accuracy: 0.9497\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.1548 - accuracy: 0.9589\n",
      "Test loss: 0.15479078888893127\n",
      "Test accuracy: 0.9588815569877625\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02c577",
   "metadata": {},
   "source": [
    "Evaluating the trained InceptionV3-based model (model) on the training (train_generator), validation (val_generator), and test (test_generator) datasets using the evaluate method. It calculates and retrieves the loss and accuracy metrics for each dataset and prints them in a clear format. Adjustments have been made to ensure the print statements display the evaluation results correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd06ab-b361-4c9b-8a3f-31661c985115",
   "metadata": {
    "id": "ebdd06ab-b361-4c9b-8a3f-31661c985115",
    "outputId": "ada43a6c-5ef2-4fd8-a352-c1f15c0b4af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 156ms/step - loss: 0.0457 - accuracy: 0.9871\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.2711 - accuracy: 0.9497\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.1548 - accuracy: 0.9589\n",
      "Train loss:, val loss: test loss:  0.04572135955095291 0.27109161019325256 0.15479077398777008\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9871428608894348 0.9497487545013428 0.9588815569877625\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0960157",
   "metadata": {},
   "source": [
    "### Building the InceptionV3 Model with a Dropout Layer and Compiling using Adagrad Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365b78d",
   "metadata": {},
   "source": [
    "Constructing a transfer learning model using the InceptionV3 architecture pretrained on ImageNet for image classification tasks. It initializes InceptionV3 without its fully connected layers (include_top=False) and adds a global average pooling layer to reduce spatial dimensions, followed by batch normalization and a dropout layer (40%) for regularization. A dense layer with 1024 units and ReLU activation further processes the features. Another batch normalization layer is applied before the final dense layer, which predicts classes based on the number of categories in train_generator using softmax activation. All layers from the InceptionV3 base model are frozen to retain pretrained weights. The model is compiled with the Adagrad optimizer, configured with a learning rate of 0.001, categorical cross-entropy loss function, and accuracy metric for model evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76459a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=  Dropout(0.4)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adagrad(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d124355",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30a7b6",
   "metadata": {
    "id": "db30a7b6",
    "outputId": "2a4747b5-ca68-421f-f9cc-44d43d67d1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSAI\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:81: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 18s 178ms/step - loss: 1.6358 - accuracy: 0.4274 - val_loss: 1.0626 - val_accuracy: 0.6684\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 1.0094 - accuracy: 0.6456 - val_loss: 0.7611 - val_accuracy: 0.7622\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 0.8143 - accuracy: 0.7287 - val_loss: 0.6125 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.7231 - accuracy: 0.7424 - val_loss: 0.5347 - val_accuracy: 0.8281\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.6363 - accuracy: 0.7887 - val_loss: 0.4904 - val_accuracy: 0.8455\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.5997 - accuracy: 0.7912 - val_loss: 0.4342 - val_accuracy: 0.8663\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.5621 - accuracy: 0.7999 - val_loss: 0.4018 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.5445 - accuracy: 0.8103 - val_loss: 0.3829 - val_accuracy: 0.8715\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.5105 - accuracy: 0.8259 - val_loss: 0.3606 - val_accuracy: 0.8837\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.4822 - accuracy: 0.8335 - val_loss: 0.3402 - val_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.4640 - accuracy: 0.8392 - val_loss: 0.3228 - val_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.4429 - accuracy: 0.8508 - val_loss: 0.3220 - val_accuracy: 0.8924\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 0.4217 - accuracy: 0.8519 - val_loss: 0.3153 - val_accuracy: 0.8976\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 176ms/step - loss: 0.4110 - accuracy: 0.8645 - val_loss: 0.2928 - val_accuracy: 0.9045\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 15s 176ms/step - loss: 0.4048 - accuracy: 0.8645 - val_loss: 0.2827 - val_accuracy: 0.9080\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.3759 - accuracy: 0.8707 - val_loss: 0.2793 - val_accuracy: 0.9132\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.3873 - accuracy: 0.8631 - val_loss: 0.2703 - val_accuracy: 0.9167\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 0.3774 - accuracy: 0.8703 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.3454 - accuracy: 0.8826 - val_loss: 0.2568 - val_accuracy: 0.9201\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 0.3599 - accuracy: 0.8764 - val_loss: 0.2517 - val_accuracy: 0.9219\n",
      "19/19 [==============================] - 1s 65ms/step - loss: 0.2354 - accuracy: 0.9424\n",
      "Test loss: 0.23535430431365967\n",
      "Test accuracy: 0.9424341917037964\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db128d-d4ee-4ee4-826f-106a35973564",
   "metadata": {
    "id": "20db128d-d4ee-4ee4-826f-106a35973564",
    "outputId": "5e4e5764-4ad4-4934-9eaa-4ad7ccb75602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 159ms/step - loss: 0.1829 - accuracy: 0.9468\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.2461 - accuracy: 0.9246\n",
      "19/19 [==============================] - 1s 64ms/step - loss: 0.2354 - accuracy: 0.9424\n",
      "Train loss:, val loss: test loss:  0.1829499453306198 0.2460925430059433 0.23535431921482086\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9467856884002686 0.9246231317520142 0.9424341917037964\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67205b63",
   "metadata": {},
   "source": [
    "### Building the InceptionV3 Model using two Dropout Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c18f3",
   "metadata": {},
   "source": [
    "Building a transfer learning model using InceptionV3, pretrained on ImageNet, for image classification tasks. The base model is loaded without its fully connected layers (include_top=False), and additional layers are added for regularization and feature extraction. It starts with a dropout layer (dropout rate of 40%) to prevent overfitting, followed by global average pooling to reduce spatial dimensions. Batch normalization layers are applied for stabilizing the training process, and another dropout layer (40%) further regularizes the model. A dense layer with 1024 units and ReLU activation processes the extracted features, followed by another batch normalization layer. The final dense layer uses softmax activation to predict classes based on the number of categories in the train_generator. All layers from the InceptionV3 base model are frozen to retain their pretrained weights. The model is compiled with the Adam optimizer, configured with a learning rate of 0.001, categorical cross-entropy loss function, and accuracy metric for model evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = Dropout(0.4)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x=  Dropout(0.4)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8def78d",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6db0a",
   "metadata": {
    "id": "4ca6db0a",
    "outputId": "2c40383a-c1d0-404e-a4ce-e3190a6355a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 18s 180ms/step - loss: 1.0431 - accuracy: 0.7392 - val_loss: 0.5410 - val_accuracy: 0.8247\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.5087 - accuracy: 0.8432 - val_loss: 0.3062 - val_accuracy: 0.9132\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.3461 - accuracy: 0.8866 - val_loss: 0.2656 - val_accuracy: 0.9132\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.2794 - accuracy: 0.9025 - val_loss: 0.2626 - val_accuracy: 0.9219\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 0.2647 - accuracy: 0.9133 - val_loss: 0.2347 - val_accuracy: 0.9271\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.2032 - accuracy: 0.9288 - val_loss: 0.1714 - val_accuracy: 0.9392\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1875 - accuracy: 0.9346 - val_loss: 0.1690 - val_accuracy: 0.9497\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.1788 - accuracy: 0.9353 - val_loss: 0.1444 - val_accuracy: 0.9549\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.1541 - accuracy: 0.9473 - val_loss: 0.1463 - val_accuracy: 0.9566\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.1523 - accuracy: 0.9465 - val_loss: 0.1743 - val_accuracy: 0.9479\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1228 - accuracy: 0.9585 - val_loss: 0.1460 - val_accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1281 - accuracy: 0.9570 - val_loss: 0.1776 - val_accuracy: 0.9462\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.1432 - accuracy: 0.9480 - val_loss: 0.1767 - val_accuracy: 0.9549\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1214 - accuracy: 0.9610 - val_loss: 0.1552 - val_accuracy: 0.9618\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1714 - val_accuracy: 0.9566\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.0838 - accuracy: 0.9707 - val_loss: 0.1471 - val_accuracy: 0.9583\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 15s 176ms/step - loss: 0.1013 - accuracy: 0.9635 - val_loss: 0.1646 - val_accuracy: 0.9583\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1007 - accuracy: 0.9639 - val_loss: 0.1619 - val_accuracy: 0.9566\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.1090 - accuracy: 0.9646 - val_loss: 0.1400 - val_accuracy: 0.9618\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 0.0891 - accuracy: 0.9711 - val_loss: 0.1360 - val_accuracy: 0.9618\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.0667 - accuracy: 0.9704\n",
      "Test loss: 0.066710464656353\n",
      "Test accuracy: 0.9703947305679321\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b94f3",
   "metadata": {},
   "source": [
    "Evaluating method to assess the performance of your InceptionV3-based model (model) on the training (train_generator), validation (val_generator), and test (test_generator) datasets. It computes and retrieves the loss and accuracy metrics for each dataset and prints them in a clear format. Adjustments have been made to ensure the print statements display the evaluation results correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344d772",
   "metadata": {
    "id": "6344d772",
    "outputId": "8c154ab2-a9d5-4e81-df3f-c5c888ebcee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 15s 161ms/step - loss: 0.0272 - accuracy: 0.9907\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.1377 - accuracy: 0.9615\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.0667 - accuracy: 0.9704\n",
      "Train loss:, val loss: test loss:  0.02722633071243763 0.13767699897289276 0.066710464656353\n",
      "Train accuracy: val accuracy:Test accuracy: 0.9907143115997314 0.9614740610122681 0.9703947305679321\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator, verbose=1)\n",
    "val_loss,val_acc = model.evaluate(val_generator, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Train loss:, val loss: test loss: ', train_loss,val_loss, test_loss)\n",
    "print('Train accuracy: val accuracy:Test accuracy:', train_acc,val_acc,test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
